{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/samanfrm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "from Rules_Class import Rules\n",
    "import functions as fn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "start=0\n",
    "end=10\n",
    "input_directory=os.path.realpath('../Data')\n",
    "result_directory=os.path.realpath('../Data')\n",
    "list_raw=pd.read_csv(input_directory+\"/trrust_conflict.csv\",sep=',',header=(0),dtype=object)\n",
    "list_raw=list_raw.iloc[start:end,]\n",
    "list_raw_result=pd.DataFrame(columns=['src_entrez','trg_entrez','srcname','trgname','find_pmid','all_pmids','mode','score','evi_pmid','evi_sent','report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  srcuid trguid pmids srcname srcentz      mode trgname trgentz\n",
      "0      1    796   NaN    AATF   26574  conflict  CDKN1A    1026\n",
      "1      1    797   NaN    AATF   26574  conflict    KLK3     354\n",
      "2      1    799   NaN    AATF   26574  conflict    TP53    7157\n",
      "3      2    804   NaN    ABL1      25  conflict    CSF1    1435\n",
      "4      3    808   NaN     AES     166  conflict   EPHA3    2042\n",
      "5      4    811   NaN     AHR     196  conflict   ABCG2    9429\n",
      "6      4    813   NaN     AHR     196  conflict    ARNT     405\n",
      "7      4    814   NaN     AHR     196  conflict   BRCA1     672\n",
      "8      4    816   NaN     AHR     196  conflict   CCND1     595\n",
      "9      4    818   NaN     AHR     196  conflict  CYP1A1    1543\n"
     ]
    }
   ],
   "source": [
    "print(list_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive=[]\n",
    "[Positive.append(line.strip().upper()) for line in open(input_directory+\"/Positive.txt\")]\n",
    "Negative=[]\n",
    "[Negative.append(line.strip().upper()) for line in open(input_directory+\"/Negative.txt\")]\n",
    "\n",
    "genes_ents=input_directory + \"/ALL_Human_Genes_Info.csv\" #NCBI\n",
    "genes=pd.read_csv(genes_ents,sep=',',header=(0))\n",
    "genes.fillna('', inplace=True)\n",
    "\n",
    "lookup_ids=pd.read_csv(input_directory+\"/ncbi_id_lookup.csv\",sep='\\t',header=(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in list_raw.itertuples():\n",
    "    #try:\n",
    "        query_id=[int(row.srcentz),int(row.trgentz)] #NCBI ID MUST [TF,Target]\n",
    "        query_genes=[row.srcname,row.trgname] #Symbol MUST [TF,Target]\n",
    "        print(query_genes)\n",
    "        query_genes, query_id,single_gene,single_id =fn.make_query(genes,lookup_ids,query_genes,query_id)\n",
    "        status=''\n",
    "        mesh=\"humans\"\n",
    "        try:\n",
    "            myterm=fn.term_maker(single_gene,genes,mesh)\n",
    "            ####  ESearch: Searching the Entrez databases\n",
    "            Entrez.email=\"saman.farahmand001@umb.edu\"\n",
    "            handle=Entrez.esearch(db=\"pubmed\", term=myterm, retmax=100000000)\n",
    "            record=Entrez.read(handle)\n",
    "            PubIDs = record[\"IdList\"]\n",
    "        except:\n",
    "            status+=\"Enterz Fetch Error|||\"\n",
    "            #print(status)\n",
    "            list_raw_result=list_raw_result.append({'src_entrez':single_id[0],'trg_entrez':single_id[1],'srcname':single_gene[0],'trgname':single_gene[1],'find_pmid':None,'all_pmids':None,'mode':None,'score':None,'evi_pmid':None,'evi_sent':None,'report':status},ignore_index=True)\n",
    "        if(len(PubIDs)>0):\n",
    "            print(len(PubIDs))\n",
    "            sum_ranks=[]\n",
    "            evi_sentence=[]\n",
    "            evi_pmids=[]\n",
    "            all_pmids=';'.join(PubIDs)\n",
    "            for PubID in PubIDs:\n",
    "                abstract=''\n",
    "                ranks=[]\n",
    "                annot_df=pd.DataFrame(columns=['type','id','text','offset','length'])\n",
    "                try:\n",
    "                    annot_df, abstract=fn.pubtator_annot(annot_df,PubID)\n",
    "                except:\n",
    "                    abstract=fn.ret_abstract(PubID)\n",
    "                    if(abstract=='?'):\n",
    "                        #print(\"PMID=[\"+PubID+\"] does not exist any more!\")\n",
    "                        continue # remove it from the output results in TRRUST\n",
    "                    else:\n",
    "                        status+=\"PMID=[\"+PubID+\"] PubTator Response is not readable, Try to annotate manually...\"\n",
    "                    #print(status)\n",
    "#                try:\n",
    "#                    beCAS_lookup_full=fn.beCAS_lookup(PubID,query_id)\n",
    "#                    beCAS_lookup=beCAS_lookup_full[['type','id','text','offset','length']]\n",
    "#                    annot_df=pd.concat([annot_df,beCAS_lookup], ignore_index=True)\n",
    "#                except:\n",
    "#                    status+=\"beCAS Server error|||\"\n",
    "\n",
    "                lookup_results=fn.lookup_annot(abstract,query_genes,query_id,lookup_ids)\n",
    "                annot_df=annot_df.append(lookup_results)\n",
    "#                surface_annot=fn.surface_similarity(abstract, genes, query_genes, query_id,lookup_ids,single_id)\n",
    "#                annot_df=annot_df.append(surface_annot)\n",
    "                annot_df=annot_df.drop_duplicates(subset=['id','offset'])\n",
    "\n",
    "                annot_df=fn.multiple_taxonomy(annot_df, query_id)\n",
    "        \n",
    "                annot_df=annot_df.reset_index(drop=True)\n",
    "                candidate_sentences, covered=fn.candidate_sentence(annot_df,abstract,query_id)\n",
    "                if(len(candidate_sentences.index)==0):\n",
    "                    status+=\"PMID=[\"+PubID+\"] No co-existed sentences found in the abstract...!\"\n",
    "                    #print(status)\n",
    "                    continue\n",
    "                for sentence in candidate_sentences.itertuples():\n",
    "                    obj=Rules(Positive,Negative,annot_df,covered,abstract,query_genes,query_id,sentence)\n",
    "                    depgraphs=fn.dep_parser('8000',sentence,annot_df,query_id,single_id,Positive,Negative,2)\n",
    "                    if(depgraphs):\n",
    "                        try:\n",
    "                            obj. multiplication_score(depgraphs, single_id)\n",
    "                        except:\n",
    "                            status+=\"PMID=[\"+PubID+\"] dependency graph score error...!\"\n",
    "                    else:\n",
    "                        status+=\"PMID=[\"+PubID+\"] dependency graph co-occurance of single ids error...!\"\n",
    "                        continue\n",
    "                    #obj.search_ranking()\n",
    "                    ranks.append(obj.rank)\n",
    "                    if(obj.rank!=0):\n",
    "                        evi_sentence.append('['+PubID+']'+sentence.sentence)\n",
    "                        evi_pmids.append(PubID)\n",
    "                if(len(ranks)!=0):\n",
    "                    sum_ranks.append(sum(ranks))\n",
    "            mode=''\n",
    "            rank_T=sum(sum_ranks)\n",
    "            if(rank_T>0):\n",
    "                mode='positive'\n",
    "            if(rank_T<0):\n",
    "                mode='negative'\n",
    "            evi_sentence='|||'.join(evi_sentence)\n",
    "            evi_pmids=';'.join(evi_pmids)\n",
    "            list_raw_result=list_raw_result.append({'src_entrez':single_id[0],'trg_entrez':single_id[1],'srcname':single_gene[0],'trgname':single_gene[1],'find_pmid':str(len(all_pmids)),'all_pmids':all_pmids,'mode':mode,'score':str(rank_T),'evi_pmid':evi_pmids,'evi_sent':evi_sentence,'report':status},ignore_index=True)\n",
    "        else:\n",
    "            status+=\"Not found any PMIDs for this interaction\"\n",
    "            #print(status)\n",
    "            list_raw_result=list_raw_result.append({'src_entrez':single_id[0],'trg_entrez':single_id[1],'srcname':single_gene[0],'trgname':single_gene[1],'find_pmid':'','all_pmids':'','mode':'','score':'','evi_pmid':'','evi_sent':'','report':status},ignore_index=True)\n",
    "    #except:\n",
    "        #print(\"general Error!!\")\n",
    "        #continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trrust_raw_result.to_csv(result_directory+\"/\"+\"output_\"+start+\"_\"+end+\".csv\",sep = '$$$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
